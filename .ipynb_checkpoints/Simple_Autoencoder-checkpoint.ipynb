{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Autoencoder\n",
    "In this notebook we will implement a simple autoencoder in Pytorch on the MNIST and Cifar dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "<img src=\"imgs/autoencoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we important all of the packages we will use. Many of these packages are standard packages that are used when creating these networks. The exception is the MNIST package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torchvision.utils \n",
    "\n",
    "\n",
    "from torchvision.datasets import MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if str(device) == \"cuda\":\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that print output should be put in a log file for view in a job submission. Next we will create the folders where we will put test output and saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================= Parameters ============================\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define these parameters before I create output folders in order to name the folder of where I want the output to live. This is helpful when you are trying out different learning rates and you want to keep track of your results.\n",
    "\n",
    "Next we will create our output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Autoencoder_batch_size_'+str(batch_size)+'_lr='+str(learning_rate)\n",
    "folder_name = '../../Documents/'+folder+'/'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "if not os.path.exists(folder_name+'/saved_models'):\n",
    "    os.mkdir(folder_name+'/saved_models')\n",
    "if not os.path.exists(folder_name+'/recons'):\n",
    "    os.mkdir(folder_name+'/recons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Normalization\n",
    "Here we pause to talk about the normalization of your inputs. We plan on using the tanh activation function at the end of this autoencoder. The tanh activation function looks like the following:\n",
    "\n",
    "<img src=\"imgs/Tanh.gif\">\n",
    "\n",
    "Note that the range of the function falls within the interval -1 to 1. We therefore need to normalize our images in order for the output to match the target. There are many papers stating that normalizing the data helps reduce any skewness resulting in faster learning.\n",
    "\n",
    "Because we are normalizing the data we need a way to undo the normalization so that we can see the images during the training process. The following helper function accomplishes this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now will create a data loader using the trasnforms in the Pytorch API. The we compose a transform which consists of all of the actions we wish to take on the data. \n",
    "\n",
    "### Transform\n",
    "You always want to convert the data to a tensor. This is the natural structure that pytorch deals with. \n",
    "You also always want to normalize the data as stated above. The arguments in the normalization function pertain to the mean and standard deviation. The first vector (0.5 , 0.5, 0.5) pertains to the mean of each channel the second vector pertains to the standard deviation. Normalize does the following to each channel:\n",
    "image = (image - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(MNIST('../../Documents/data', train=True,download=True,\n",
    "                                                transform = img_transform),batch_size=batch_size,shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(MNIST('../../Documents/data',train=False,download=True,\n",
    "                                               transform=img_transform),batch_size=10000,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 469 batches for training.\n",
      "There is 1 batch for training.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} batches for training.'.format(len(train_loader)) )\n",
    "print('There is {} batch for training.'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to sample one batch from the train loader. Remember this is a list structure and each item in the list is a batch. The batch is a tensor containing all of the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([3, 482, 242])\n",
      "torch.Size([482, 242, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAAD8CAYAAACLp21tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJJgpXhWTYKZ4VUyCmeJVMQlmilfl/wEUUc+4tbE+zwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a3a03c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract batch from train loader\n",
    "sample_batch,_ = next(iter(test_loader))\n",
    "sample_batch = sample_batch[0:128,:,:,:]\n",
    "print(sample_batch.shape)\n",
    "\n",
    "# Use the denormalization function to change the sample batch\n",
    "sample_pics = to_img(sample_batch)\n",
    "print(sample_pics.shape)\n",
    "print(torchvision.utils.make_grid(sample_pics,nrow=8).shape)\n",
    "print(torchvision.utils.make_grid(sample_pics,nrow=8).permute(1,2,0).shape)\n",
    "# Use plt.imshow to display the images\n",
    "plt.imshow(torchvision.utils.make_grid(sample_pics,nrow=8).permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "# Save target training batch\n",
    "torchvision.utils.save_image(sample_pics, '../../Documents/Autoencoder_batch_size_128_lr=0.001/recons/target.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Network\n",
    "The neural network is built in a python class structure using the nn.Module call. Here we will build the encoder and the decoder separately and then create a forward function that calls both and makes up the feed forward aspect of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,1*28*28)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(-1,1,28,28)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now attach the model and the loss function to the hardware and define our optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "We implement the training of the model using a couple of for loops. One for the epochs and one for the iterations across the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.1892\n",
      "epoch [2/100], loss:0.1829\n",
      "epoch [3/100], loss:0.1599\n",
      "epoch [4/100], loss:0.1609\n",
      "epoch [5/100], loss:0.1549\n",
      "epoch [6/100], loss:0.1536\n",
      "epoch [7/100], loss:0.1436\n",
      "epoch [8/100], loss:0.1399\n",
      "epoch [9/100], loss:0.1437\n",
      "epoch [10/100], loss:0.1382\n",
      "epoch [11/100], loss:0.1494\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ee82fe06a670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# ===================forward=====================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_tensor_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensor is not a torch image.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# TODO: make efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m_is_tensor_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_tensor_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36mis_tensor\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mObject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        img, _ = data\n",
    "        img = Variable(img).to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data.item()))\n",
    "    output_val = model(Variable(sample_batch).to(device))\n",
    "    loss_val = criterion(output_val, Variable(sample_batch).to(device))\n",
    "    print('Validation Loss: {:.4f}'.format(loss_val.data.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        output_sample = model(Variable(sample_batch).to(device))\n",
    "        output_sample = to_img(output_sample.cpu()).data\n",
    "        torchvision.utils.save_image(output_sample, '../../Documents/Autoencoder_batch_size_128_lr=0.001/recons/image_{}.png'.format(epoch+1))\n",
    "\n",
    "#torch.save(model.state_dict(), './autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
