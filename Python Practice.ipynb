{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Practice notebook \n",
    "This notebook contains some of the practices I have implemented in the past when training networks in pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating subdirectories for your output\n",
    "Often it is necessary to create a folder and subdirectories for your output. This is done with the python package ```os``` You first need to import the package:\n",
    "```import os```\n",
    "\n",
    "And then you will create the following logical statements:\n",
    "\n",
    "```folder_name = '<insert_folder_name_and_location>'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "if not os.path.exists(folder_name+'/saved_models'):\n",
    "    os.mkdir(folder_name+'/saved_models')\n",
    "if not os.path.exists(folder_name+'/recons'):\n",
    "    os.mkdir(folder_name+'/recons')\n",
    "if not os.path.exists(folder_name+'/plots'):\n",
    "    os.mkdir(folder_name+'/plots')\n",
    " ```\n",
    " \n",
    " The if not ```os.path.exists``` function looks for the folder in the directory tree and returns a ```True``` boolean value if it doesn't exists. The ```os.mkdir``` flag will then make the directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a GPU flag\n",
    "By creating a GPU flag you will not have to change your code in order to run it on a cpu or gpu. The flag detects which hardware you are attempting to use and informs pytorch. One major benefit is that it allows you to prototype on your personal computer and then run the code on a GPU cluster. \n",
    "\n",
    "You will need to import the torch package and create the device variable as follows:\n",
    "\n",
    "```device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if str(device) == \"cuda\":\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    print('Using CPU')```\n",
    "\n",
    "The device variable will carry the string cuda or cpu depending on which resource is available. Once device is defined, in order to apply it to the necessary variables you would use\n",
    "\n",
    "```net = FCNet().to(device)\n",
    "content_criterion = nn.MSELoss().to(device)```\n",
    "\n",
    "The ```.to(device)``` operation sends the necessary item to the GPU or device, in this case the loss function and the network. NOTE: You must also use this when defining variables for training \n",
    "\n",
    "```for i,data in enumerate(train_loader,0):\n",
    "        inputs,target = data\n",
    "        inputs = Variable(inputs).to(device)\n",
    "        target = Variable(target).to(device)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Log file ###\n",
    "It is often helpful to create a log file particularly when you cannot see the evaulation of the loss function during training. It is also useful to compare architectures after. A simple text log file can be created using the following:\n",
    "\n",
    "```import datetime\n",
    "now = datetime.datetime.now()\n",
    "with open(folder_name+'/log+str(now)+'.txt, 'a') as log:\n",
    "    log.write('Epochs {}, batch size {}, learning rate:{:.6f}\\n'.format(num_epochs, batch_size, learning_rate))```\n",
    "    \n",
    "The now variable contains information about when the log is created and will be used to name the log. We provide the with open function the location where we want the log file as well as the name of the log file. The first line of the log file will contain information about the number of Epochs we will use, batch size and learning rate. Care should be taken to end each adendum to the log with \\n so that a new line will be used when adding to the log. \n",
    "\n",
    "Now that the log has been created it can be edited in exactly the same way, by opening the file and adding to them.\n",
    "\n",
    "One thing I find helpful is printing the GPU or CPU flag output to the log in order to make sure I am running it on the appropriate device. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Models \n",
    "\n",
    "Often it is important to save the models during training. The important items to store from a model either to continue training or to perform inference are the parameters the model, the optimizer and the loss function etc. \n",
    "\n",
    "Pytorch saves the parameters in a dictionary. Which can be viewed by performing\n",
    "\n",
    "```print(\"The state dict keys: \\n\\n, model.state_dict().keys())```\n",
    "\n",
    "The state dict keys: \n",
    "\n",
    " ```odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias'])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to reconstruct the model exactly as it was when we trained at loading time so we need to store information about the model architecture in the state_dict. First create the dictionary 'checkpoint'\n",
    "\n",
    "```checkpoint = {'epoch': epoch,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict' : optimizer.state_dict()\n",
    "                  'loss':loss,\n",
    "                  ...}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to save we use \n",
    "```torch.save(checkpoint, 'checkpoint.pth')```\n",
    "\n",
    "It should be noted that you can save anything you want within the checkpoint dictionary but the most important for training later are the state_dict and the optimizer state_dict.\n",
    "\n",
    "It is worth noting that it is convention to save the model with a ```.pth``` extenstion. I typically also incorporate the epoch information in the same of the model save. \n",
    "\n",
    "```epoch_save_autoencoder = folder_name+'/saved_models/autoencoder_Epoch_'+str(epoch)+'.pth'\n",
    "torch.save(checkpoint,epoch_save_autoencoder)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the models\n",
    "In order to load the model we need to create the model and the optimizer\n",
    "\n",
    "```\n",
    "model = TheModelClass(*args,**kwargs)\n",
    "\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss'] \n",
    "\n",
    "\n",
    "model.eval()\n",
    "# or\n",
    "model.train()```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singularity Basics\n",
    "There are newer versions of singularity available. The IT assistants will be best to help you with your installation, but there are a couple basics you should know. For the most part, your mentor or the IT department shoudl have working containers or recipes. \n",
    "\n",
    "### Recipe \n",
    "A singularity recipe is essentially what you would run to install all packages that you need. \n",
    "\n",
    "\n",
    "```\n",
    "Bootstrap: shub\n",
    "From: singularityhub/ubuntu\n",
    "\n",
    "%runscript\n",
    "    exec echo \"The runscript is the containers default runtime command!\"\n",
    "\n",
    "%files\n",
    "   /home/vanessa/Desktop/hello-kitty.txt        # copied to root of container\n",
    "   /home/vanessa/Desktop/party_dinosaur.gif     /opt/the-party-dino.gif #\n",
    "\n",
    "%environment\n",
    "    VARIABLE=MEATBALLVALUE\n",
    "    export VARIABLE\n",
    "\n",
    "%labels\n",
    "   AUTHOR vsochat@stanford.edu\n",
    "\n",
    "%post\n",
    "    apt-get update && apt-get -y install python3 git wget\n",
    "    mkdir /data\n",
    "    echo \"The post section is where you can install, and configure your container.\"\n",
    "```\n",
    "\n",
    "To build the recipe use\n",
    "\n",
    "```sudo singularity build ubuntu.simg Singularity```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with Singularity containers\n",
    "\n",
    "There are two ways you will be interacting with the containers, you will either execute the container or operate it in a shell\n",
    "\n",
    "Within a shell you will access the inside of a container like a small virtual machine. In conjunction with an interactive shell you would first use ```srun``` to start the interactive session and then use \n",
    "\n",
    " ``singularity shell hello-world.simg\n",
    "Singularity: Invoking an interactive shell within container...```\n",
    "\n",
    "The alternative is to execute a command. This is more appropriate when you send a job to the cluster. This would be a line in your bash submission script that reads\n",
    "\n",
    "```singularity exec hello-world.simg python_script.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
